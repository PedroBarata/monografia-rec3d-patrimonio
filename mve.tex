\doublespacing
\section{MVE -- \emph{Multi-View Reconstruction Environment}}\label{sec:mve}
%======================================================================================
%

\doublespacing

\subsection{Introdução}
Um dos sistemas de pesquisa de ponta mais utilizados para a técnica de reconstrução densa é o MVE --
\emph{Multi-View Reconstruction Environment}~\cite{mve}. Este algoritmo utiliza
fotos e produz uma malha triangular superficial como resultado. Diferentemente
das reconstruções baseadas nas geometrias das imagens, o MVE é focado na
reconstrução multi-escala, um quesito importante na reconstrução de esculturas e
acervo cultural. Portanto, com esta técnica é possível reconstruir grandes
volumes de dados, contendo regiões detalhadas em alta resolução, em comparação
com o resto da cena. O sistema ainda possui uma interface gráfica para uma
reconstrução baseada no SfM, amigável ao usuário e conhecida como UMVE, que
permite a visualização e inspeção das imagens, mapas de profundidade e
renderizar cenas e malhas 3D. Sua base de operação é basicamente
\ref{fig:mvepipeline}:
\begin{enumerate}[leftmargin=2.5cm]
\item{Estrutura por Movimento -- \emph{Structure-from-Motion} (SfM):}

\begin{itemize}[leftmargin=2.5cm]
\item{
Reconstrói os parâmetros externos da câmera (posição e orientação) e seus
parâmetros internos de calibração (distância focal e distorção radial), encontrando correspondências
esparsas, mas estáveis entre as imagens.
}
\end{itemize}

\item{Estereoscopia multiocular -- \emph{Multi-View Stereo} (MVS):}
\begin{itemize}[leftmargin=2.5cm]
\item{
Utiliza a posição estimada das câmeras, encontrando as correspondências visuais
nas imagens. Estas correspondências são trianguladas, produzindo a informação
3D, e, consequentemente a reconstrução 3D densa.
} 
\end{itemize}
\item{Reconstrução de superfícies -- \emph{Surface Reconstruction}:}
\begin{itemize}[leftmargin=2.5cm]
\item{
Tem como entrada uma densa nuvem de pontos, ou mapas de profundidade
individuais. Produz uma malha superficial globalmente consistente.
}
\end{itemize}
\end{enumerate}

\newpage

\begin{figure}[!h]
	\centering
	\caption{Funcionamento do MVE}
	\includegraphics[width=\linewidth]{figs/mvepipe.png}
	\note{%
  Começando com múltiplas imagens, técnicas SfM são
  empregadas para recontruir os parâmetros das câmeras e os conjuntos de pontos
  esparsos. Mapas de profundidade são computados para cada imagem usando o MVS.
  Finalmente, uma malha colorida é extraída da união de todos os mapas de
  profundidade usando um algoritmo de aproximações de reconstruções de
  superfícies, FSSR -- \emph{Floating Scale Surface Reconstruction}.
	}
\source{
	 \citeauthor{mve},
   	 \citeyear{mve}.
   }
   \label{fig:mvepipeline}
\end{figure}

Como não existem muitas opções para algoritmos de SfM, o MVE permite a
utilização de softwares externos como o
\emph{Bundler}~\cite{snavely2010bundler} ou o prório VisualSfM para esta
etapa.  Tendo o SfM feito, partimos para o MVS. Com os parâmetros
de câmera conhecidos, a reconstrução densa geométrica é feita. Existem diversos
algoritmos para a reconstrução densa; o MVE utiliza um algoritmo
próprio, bastante popular, feito por um de seus criadores, Michael
Goesele~\cite{goesele2007multi}, que reconstrói um mapa de profundidade para
cada foto. 

Embora abordagens baseadas em mapeamentos de profundidade produzam uma grande
quantidade de redundâncias, (isso se dá por causa das inúmeras fotos que são
sobrepostas e possuem partes similares da mesma cena), este algoritmo é
altamente escalável para grandes cenas, pois apenas um pequeno conjunto de fotos
vizinhas é necessário para a reconstrução. Outra vantagem da utilização dos
mapas de profundidade como representação intermediária é que a geometria é
parametrizada em seu domínio natural, e os dados por foto (como a cor, por
exemplo) estão diretamente acessíveis nas imagens.

\subsection{Guia de reconstrução com o MVE}
Existem algumas recomendações para se ter uma boa reconstrução com o MVE~\cite{mve}.
Um bom conjunto de dados é gerado se algumas regras simples forem seguidas:

\begin{itemize}[leftmargin=2.5cm]

\item{Para que o algoritmo MVS consiga fazer uma triangulação com qualquer
  posição 3D, o conjunto de dados terá que ter, no mínimo, cinco fotos.}

\item{As fotos devem ser tiradas com uma boa quantidade de sobreposição. A menos que o conjunto de dados se torne muito grande, uma grande quantidade de fotos não prejudicará a qualidade. 
Mas terá uma compensação do sistema, no que diz respeito à qualidade e desempenho.}

\item{Para a triangulação funcionar, é necessário que tenha o efeito de paralaxe
    \ref{fig:parallax}.}

\item{A câmera deverá ser reposicionada, de preferência.}

\end{itemize}

\begin{figure} [!h]
	\centering
	\caption{Funcionamento da paralaxe}
	\includegraphics[width=0.2\linewidth]{figs/parallaxA.png}(a)
	\includegraphics[width=0.2\linewidth]{figs/parallaxB.png}(b)
	\includegraphics[width=0.2\linewidth]{figs/parallaxC.png}(c)
	\legend{%
  (a) - espaçamento grande entre câmeras; (b) - disposição correta das câmeras; (c) - espaçamento pequeno entre câmeras.
	}
	\note{%
		Com espaçamento grande entre câmeras, a informação extraída das
  imagens em comum é menor. Se a angulação do efeito de paralaxe for
  baixa, terá a mesma informação sobre um ponto 3D.
  Nesses casos, a reconstrução pode ser incerta. Para que
  o efeito paralaxe tenha maior proveito das imagens, alguns autores argumentam que
  câmeras devem estar dispostas como, de forma a extrair uma boa
  quantidade e qualidade de informações do ponto.
	}
	\source{
   	 \citeauthor{3DCompVision2Didier},
   	 \citeyear{3DCompVision2Didier}.
   }
	\label{fig:parallax}
\end{figure}


\subsubsection{Criando uma cena}

Uma vista (\emph{view}) no MVE contém dados por \emph{viewport} (como imagens,
mapas de profundidade ou outros dados). Uma cena é uma coleção de vistas que
formam um conjunto de dados (\emph{dataset}). Uma nova cena pode ser criada
utilizando a interface gráfica UMVE, Figura~\ref{fig:umve:gui}, ou por linha de
comando (\emph{makescene}).  Tecnicamente, a cena é criada como um diretório no
sistema de arquivos (com o nome do conjunto de dados). Este, por sua vez, contém
outro diretório (\emph{views}), com todas as vistas guardadas com uma extensão
de arquivos em\ \texttt{.MVE}.

Criar uma nova cena também criará apenas o diretório (\emph{views}) vazio. A
importação de fotos criará arquivos .MVE para cada foto. Esse processo importará
metadados provenienteas das imagens (\emph{tags} EXIF), que é necessário para
estimar a distância focal para cada foto a partir do modelo de câmera gravado em
determinados tipos de arquivos de imagem. Caso estes meta-dados não estejam
disponíveis, uma distância focal padrão é assumida pelo sistema, porém se essa
distância adotada for uma péssima suposição, com relação ao conjunto de dados
utilizado, podem acontecer erros no SfM.

\newpage

\begin{figure}[!h]
	\centering
	\caption{%
	Interface gráfica (UMVE)%\cite{Cui:Theobalt:etal:PAMI2013,Pajdla:etal:ICCV2011}.
	}
	%   \includegraphics[width=1.0\linewidth]{figs/3d-curve-sketch/system-diagram.eps}
	\includegraphics[width=\linewidth]{figs/umve1.png}
	\source{
   	 O autor,
   	 2017.
   }
	\label{fig:umve:gui}
\end{figure}
% SfM reconstruction: The SfM reconstruction can be con-
% figured and started using UMVE, or the command line tool
% sfmrecon. The UI guides through feature detection, pairwise
% matching and incremental SfM. What follows is the SfM re-
% construction starting from an initial pair, and incrementally
% adding views to the reconstruction. Finally, the original im-
% ages are undistorted and stored in the views for the next step.
% Figure 8 shows a rendering of the SfM reconstruction with
% the sparse point cloud and the camera frusta. Note how dense
% the frusta are spaced around the object to achieve a good re-
% construction.
\subsection{Reconstrução SfM}

Pode ser configurada e iniciada a SfM usando a interface gráfica UMVE ou por linha de
comando (\texttt{sfmrecon}). A interface guia através da detecção de
\emph{features}, casamento de todos os pares de imagens (\emph{pairwise matching}) e uso
incremental do SfM. A reconstrução SfM começa a partir de um
par inicial, e adiciona, de forma incremental, mais vistas à
reconstrução~\ref{fig:mvesfm}.

\newpage

\begin{figure}[!h]
	\centering
		\caption{%
  Reconstrução de nuvem de pontos gerada a partir de
  SfM do MVE%\cite{Cui:Theobalt:etal:PAMI2013,Pajdla:etal:ICCV2011}.
	}
	\includegraphics[width=\linewidth]{figs/umve5sfm.png}
	\source{
   	 O autor,
   	 2017.
   }\label{fig:mvesfm}
\end{figure}


%
%MVS reconstruction: Given images with camera parameters,
%dense geometry is reconstructed using MVS. This can
%be done with either UMVE or the command line tool dmrecon.
%The most important parameter is the resolution level at
%which depth maps are reconstructed. A level of 0, or L0, reconstructs
%at the original image size, L1 corresponds to half
%the size (quarter the number of pixels), and so one. Looking
%at the resolution of recent digital cameras, a full-size L0
%reconstruction is rarely useful as finding dense correspondences
%gets more difficult, often leading to sparser depth
%maps at much higher computational cost. Using smaller images
%(we often use L2), the process is faster and depth maps
%become more complete. See Figure 9 for a depth map computed
%at L2.
\subsubsection{Estereoscopia Multiocular -- \emph{Multi-View Stereo} (MVS)}

Usando as imagens junto com os parâmetros obtidos das câmeras, é possível
reconstruir a geometria densa utilizando o MVS. Isso pode ser feito utilizando a
interface gráfica (UMVE) ou por linha de comando (\emph{dmrecon}).
O parâmetro mais importante é o nível de resolução em que os mapas de
profundidade são reconstruídos: Caso seja nível 0 (ou L0), a reconstrução é
feita usando o tamanho original das imagens. Se for nível 1 (ou L1), a
reconstrução corresponde à metade do tamanho (um quarto dos números de pixels),
e assim por diante.

Com a alta resolução das câmeras atuais, uma reconstrução L0 é raramente usada, pois
geram mapas de profundidade mais dispersos com um custo computacional elevado, o
que acarreta em dificuldades para encontrar as correspondências densas das
imagens. Geralmente utiliza-se o L2, pois o processo é mais rápido, gerando
mapas de profundidades completos, já que utiliza resoluções menores, Figura~\ref{fig:mvedepth}.

\begin{figure}[!h]
	\centering
	\caption{Representação do mapa de profundidade do MVS}
	\includegraphics[width=0.7\linewidth]{figs/mvedepth.png}
	\legend{%
  Uma imagem de entrada (esquerda) e correspondência em mapas de
  profundidade (direita), em roxo as partes sem nenhum mapa naquela região.
	}
	\source{
	 \citeauthor{mve},
   	 \citeyear{mve}.
   }
   \label{fig:mvedepth}
\end{figure}

O algoritmo do MVS pode ser dividido em duas partes

\begin{itemize}[leftmargin=2.5cm]
\item {Uma estrutura regional-crescente que tem uma fila de candidatos
  correspondentes, $Q$, ordenada pelas localizações dos pixels na câmera
acrescido de seus valores para profundidade e normais;}
\item {Um sistema de correspondências que leva um candidato correspondente como
  entrada e calcula profundidade, normal e uma confiança de correspondência
usando vistas vizinhas fornecidas pela seleção de exibição local. Se a
correspondência for bem sucedida, os dados são armazenados em mapas de
profundidade, normais e de confiança e os pixels vizinhos na câmera são
adicionados como novos candidatos a $Q$.}
\end{itemize}

\subsubsection{Reconstrução de Superfícies -- \emph{Surface Reconstruction}}

Utiliza-se o programa em linha de comando \texttt{scene2pet}, que combina todos os mapas de
profundidade em uma única e grande nuvem de pontos. Nesta fase, um valor de
escala é atribuído a cada ponto, que indica o tamanho atual da região da
superfície na qual o ponto foi mensurado. Esta informação adicional permite o
uso de várias propriedades benéficas usando a abordagem de reconstrução de
superfície por FSSR~\cite{fuhrmann2014floating}.  A seguir, as ferramentas
FSSR calculam uma representação volumétrica de escala múltipla a partir dos
pontos (na qual não precisa de nenhum ajuste de parâmetros explícitos) e uma
malha final é extraída. Esta malha pode parecer desordenada devido a regiões não
confiáveis e a componentes isolados, oriundos de medidas imprecisas. Logo, a
malha é limpa, retirando pequenos componentes isolados e regiões não confiáveis
da superfície. 

% Experiência com o MVE: A utilização do software é bem intuitiva, seja por linha de comando ou pela interface gráfica (neste modo, fica mais fácil visualizar cada etapa da reconstrução). Amplamente configurável, podendo escolher a vizinhança, escala, manter o mapa de profundidade, ver os dados \emph{EXIF} de cada imagem, dentre outras configurações.

% Entretanto, para a aplicação proposta neste projeto, não é muito interessante, visto que ele utiliza a informação das câmeras (\emph{EXIF}) e das imagens e, como as imagens empregadas na reconstrução são, tecnicamente, vídeos cortados em determinados \emph{frames}, não é possível obter a informação das câmeras \ref{fig:mveexif}, logo o software não tem tanta aplicabilidade neste caso, pois recai no problema dos parâmetros padrões adotados para as câmeras não serem bons o suficiente para estes conjuntos de dados, a menos que sejam tiradas fotos sequenciais de alguma escultura ou objeto que se deseja gerar a reconstrução densa, pois dessa forma, as informações necessárias das câmeras estarão armazenadas.

% \begin{figure}[!h]
% 	\centering
% 	\includegraphics[width=0.5\linewidth]{figs/exifumve.png}(a)
% 	\includegraphics[width=0.5\linewidth]{figs/exifsemumve.png}(b)
% 	\caption{%
% 	A figura (a) é um exemplo onde a imagem possui dados na extensão \emph{EXIF} (destacado em azul). Ao passo que a figura (b) é um frame de um vídeo, que não possui os dados das câmeras (destacado em azul).
% 	%\cite{Cui:Theobalt:etal:PAMI2013,Pajdla:etal:ICCV2011}.
% 	}\label{fig:mveexif}
% \end{figure} 

% Com isso em mente, foi gerada uma reconstrução de um vídeo gravado de uma escultura no Jardim do Nêgo. O  vídeo foi cortado em \emph{frames} onde foram geradas 200 imagens base. 

% A partir disso, foi executado, todos os passos de uma reconstrução utilizando o MVE, de forma que, foram utilizadas as duas opções, tanto por linha de comando, quanto pela interface gráfica (UMVE).

% Pela interface gráfica, o processo todo de reconstrução foi rápido (cerca de 30 minutos) \ref{fig:UMVEdense}, ao passo que por linha de comando, levou cerca de 11 horas e 30 minutos. 

% O UMVE não sinaliza quando o processo em execução termina, então, a explicação para essa discrepância no tempo é devido à execução de outro comando, sobrepondo o que já estava sendo executado, sem deixar terminá-lo.

% \begin{figure}[!h]
% 	\centering
% 	\includegraphics[width=0.5\linewidth]{figs/umvedense.png}
% 	\caption{%
% 	Final da reconstrução via UMVE, percebe-se que alguns pontos não foram considerados, tendo como resultado uma "nuvem de pontos" mais densa, basicamente.
% 	%\cite{Cui:Theobalt:etal:PAMI2013,Pajdla:etal:ICCV2011}.
% 	}\label{fig:UMVEdense}
% \end{figure} 

% Na reconstrução por linha de comando também é possível visualizar em qual etapa da execução o algoritmo está \ref{fig:passosMVE}, configurar alguns parâmetros e inclusive mostrar a porcentagem de progresso do comando. Foram executados os comandos declarados nesta seção.  O \emph{sfmrecon} demorou cerca de 1 minuto e meio \ref{fig:MVESfM}.

% \begin{figure}[!h]
% 	\centering
% 	\includegraphics[width=0.5\linewidth]{figs/umve2sfm.png} (a)
% 	\includegraphics[width=0.5\linewidth]{figs/umve3sfmfeature.png} (b)
% 	\includegraphics[width=0.5\linewidth]{figs/umve4ba.png} (c)
% 	\caption{%
% 	Processos dentro do comando \emph{sfmrecon}, onde (a) estão sendo detectadas as \emph{features} do conjunto de imagens. Em (b) está computado o \emph{pairwise matching} e em (c) está no processo de \emph{Bundle Adjustment}~\cite{bundleAdjustmentSlide}, usando condições-padrão para as câmeras.
% 	%\cite{Cui:Theobalt:etal:PAMI2013,Pajdla:etal:ICCV2011}.
% 	}\label{fig:passosMVE}
% \end{figure} 

% \begin{figure}[!h]
% 	\centering
% 	\includegraphics[width=0.8\linewidth]{figs/sfmmve.png}
% 	\caption{%
% 	Término do comando \emph{sfmrecon}, onde demorou cerca de 1 minuto e meio (75509 milisegundos).
% 	%\cite{Cui:Theobalt:etal:PAMI2013,Pajdla:etal:ICCV2011}.
% 	}\label{fig:MVESfM}
% \end{figure}

% O próximo comando, \emph{dmrecon} demorou cerca de 4 horas, usando como configuração um nível L2, com 20 vizinhos \ref{fig:MVEDenseRecon}. Usando um nível L0, o algoritmo rodou durante 6 horas aproximadamente e foi cancelado devido à demora na execução. 

% \begin{figure}[!h]
% 	\centering
% 	\includegraphics[width=0.8\linewidth]{figs/umvetempo.png}
% 	\caption{%
% 	Término do comando \emph{dmrecon}, onde demorou cerca de 4 horas (14502576 milisegundos).
% 	%\cite{Cui:Theobalt:etal:PAMI2013,Pajdla:etal:ICCV2011}.
% 	}\label{fig:MVEDenseRecon}
% \end{figure} 

% Usando o \emph{scene2pet}, é necessário em qual nível estamos reconstruindo e também uma saída válida. Por exemplo: "scene2pset.exe -Fnivel cena output". Onde o nível poderá ser um 0 (-F0), 1 (-F1) e assim por diante, a cena é o \emph{input} e o \emph{output} é um arquivo de extensão configurável, neste caso \emph{.ply} \ref{fig:MVEScene2Pet}. Este comando foi rápido, demorou cerca de 10 minutos, levando em conta todos os níveis.

% \begin{figure}[!h]
% 	\centering
% 	\includegraphics[width=0.8\linewidth]{figs/mvemesh.png}
% 	\caption{%
% 	Execução dos comandos \emph{scene2pset}, nos níveis -F0, -F1, -F2 e -F3.
% 	%\cite{Cui:Theobalt:etal:PAMI2013,Pajdla:etal:ICCV2011}.
% 	}\label{fig:MVEscene2pset}
% \end{figure} 

% Para juntar todos os níveis do \emph{scene2pset}, foi usado o \emph{fssrecon}, que gera uma única reconstrução. Este processo demorou bastante, cerca de 7 horas \ref{fig:MVEFSSR}. Que teve como resultado a malha \ref{fig:MVEFSSRMesh}.

% \begin{figure}[!h]
% 	\centering
% 	\includegraphics[width=0.8\linewidth]{figs/mvemeshtempo2.png}
% 	\caption{%
% 	Progressão do comando \emph{fssrecon}, onde possui o ETA -- \emph{Estimated Time of Arrival}.
% 	%\cite{Cui:Theobalt:etal:PAMI2013,Pajdla:etal:ICCV2011}.
% 	}\label{fig:MVEFSSR}
% \end{figure} 

% \begin{figure}[!h]
% 	\centering
% 	\includegraphics[width=1\linewidth]{figs/mvemeshout.png}
% 	\caption{%
% 	Malha com ruídos proveniente do comando \emph{fssrecon}.
% 	%\cite{Cui:Theobalt:etal:PAMI2013,Pajdla:etal:ICCV2011}.
% 	}\label{fig:MVEFSSRMesh}
% \end{figure} 

% Finalmente, basta limpar a malha atual com o comando \emph{meshclean}, onde foi obtido o resultado \ref{MVEMeshClean}.

% \begin{figure}[!h]
% 	\centering
% 	\includegraphics[width=1\linewidth]{figs/mvemeshclean.png}
% 	\caption{%
% 	Resultado final, após a remoção dos ruídos da malha.
% 	%\cite{Cui:Theobalt:etal:PAMI2013,Pajdla:etal:ICCV2011}.
% 	}\label{fig:MVEMeshClean}
% \end{figure} 
